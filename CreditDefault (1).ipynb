{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Default\n",
    "#### Josep Puig Sall√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to predict which clients will default. I have used the **Credit Card DataSet** and I've done it with **pyspark**. I try to solve it by training several machine learning techniques and show how they behave within the sample and out of the sample train. \n",
    "\n",
    "There are some techniques that are not thought to use in this kind of dataset, I only want to prove some models for classifying.\n",
    "\n",
    "This is my first post in Github and moreover, I have learned spark in the last two months so, please, if you see any mistake or anything you think that could be better, write a comment.\n",
    "\n",
    "This post has to parts, the first one, I use *spark SQL* to do some exploratory analysis. And, in the second part, some Machine Learning models are used to predict the default clients. \n",
    "\n",
    "The problem with spark is that I cannot make plots to show the results like in R or python. \n",
    "\n",
    "The first thing to do is to establish the spark environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/conda/bin/python3'\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second thing is to download the data and quit the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  '20000',\n",
       "  '2',\n",
       "  '2',\n",
       "  '1',\n",
       "  '24',\n",
       "  '2',\n",
       "  '2',\n",
       "  '-1',\n",
       "  '-1',\n",
       "  '-2',\n",
       "  '-2',\n",
       "  '3913',\n",
       "  '3102',\n",
       "  '689',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '689',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '1'],\n",
       " ['2',\n",
       "  '120000',\n",
       "  '2',\n",
       "  '2',\n",
       "  '2',\n",
       "  '26',\n",
       "  '-1',\n",
       "  '2',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '2',\n",
       "  '2682',\n",
       "  '1725',\n",
       "  '2682',\n",
       "  '3272',\n",
       "  '3455',\n",
       "  '3261',\n",
       "  '0',\n",
       "  '1000',\n",
       "  '1000',\n",
       "  '1000',\n",
       "  '0',\n",
       "  '2000',\n",
       "  '1'],\n",
       " ['3',\n",
       "  '90000',\n",
       "  '2',\n",
       "  '2',\n",
       "  '2',\n",
       "  '34',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '29239',\n",
       "  '14027',\n",
       "  '13559',\n",
       "  '14331',\n",
       "  '14948',\n",
       "  '15549',\n",
       "  '1518',\n",
       "  '1500',\n",
       "  '1000',\n",
       "  '1000',\n",
       "  '1000',\n",
       "  '5000',\n",
       "  '0'],\n",
       " ['4',\n",
       "  '50000',\n",
       "  '2',\n",
       "  '2',\n",
       "  '1',\n",
       "  '37',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '46990',\n",
       "  '48233',\n",
       "  '49291',\n",
       "  '28314',\n",
       "  '28959',\n",
       "  '29547',\n",
       "  '2000',\n",
       "  '2019',\n",
       "  '1200',\n",
       "  '1100',\n",
       "  '1069',\n",
       "  '1000',\n",
       "  '0'],\n",
       " ['5',\n",
       "  '50000',\n",
       "  '1',\n",
       "  '2',\n",
       "  '1',\n",
       "  '57',\n",
       "  '-1',\n",
       "  '0',\n",
       "  '-1',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '8617',\n",
       "  '5670',\n",
       "  '35835',\n",
       "  '20940',\n",
       "  '19146',\n",
       "  '19131',\n",
       "  '2000',\n",
       "  '36681',\n",
       "  '10000',\n",
       "  '9000',\n",
       "  '689',\n",
       "  '679',\n",
       "  '0'],\n",
       " ['6',\n",
       "  '50000',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  '37',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '64400',\n",
       "  '57069',\n",
       "  '57608',\n",
       "  '19394',\n",
       "  '19619',\n",
       "  '20024',\n",
       "  '2500',\n",
       "  '1815',\n",
       "  '657',\n",
       "  '1000',\n",
       "  '1000',\n",
       "  '800',\n",
       "  '0'],\n",
       " ['7',\n",
       "  '5e+05',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  '29',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '367965',\n",
       "  '412023',\n",
       "  '445007',\n",
       "  '542653',\n",
       "  '483003',\n",
       "  '473944',\n",
       "  '55000',\n",
       "  '40000',\n",
       "  '38000',\n",
       "  '20239',\n",
       "  '13750',\n",
       "  '13770',\n",
       "  '0']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0 = sc.textFile('./UCI_Credit_Card.csv')\n",
    "header = d0.first()\n",
    "d1 = d0.filter(lambda line: line != header)\n",
    "d2 = d1.map(lambda x: x.split(','))\n",
    "d2.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define some functions to explore the data: Gender, Education and Marriage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gender(x):\n",
    "    if int(x) == 2:\n",
    "        return 'Female'\n",
    "    else: return 'Male'\n",
    "def Education(x):\n",
    "    if int(x) == 1:\n",
    "        return 'GraduateSchool'\n",
    "    elif int(x) ==2:\n",
    "        return 'University'\n",
    "    elif int(x) == 3:\n",
    "        return 'HighSchool'\n",
    "    else: return 'Unknown'\n",
    "\n",
    "def Marriage(x):\n",
    "    if int(x) == 1:\n",
    "        return 'Married'\n",
    "    elif int(x) ==2:\n",
    "        return 'Single'\n",
    "    else: return 'Others'\n",
    "\n",
    "def Default(x):\n",
    "    if int(x)==1:\n",
    "        return 'Yes'\n",
    "    else: return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "datosExp = d2.map(lambda x: Row(\n",
    "        Default = Default(x[24]),\n",
    "        Limit_Bal = float(x[1]),\n",
    "        sex = Gender(x[2]),\n",
    "        Education = Education(x[3]),\n",
    "        Marriage = Marriage(x[4]),\n",
    "        Age = int(x[5]),\n",
    "        Pay_0 = float(x[6]),\n",
    "        Pay_2 = float(x[7]),\n",
    "        Pay_3 = float(x[8]),\n",
    "        Pay_4 = float(x[9]),\n",
    "        Pay_5 = float(x[10]),\n",
    "        Pay_6 = float(x[11]),\n",
    "        Bill_amt1 = float(x[12]),\n",
    "        Bill_amt2 = float(x[13]),\n",
    "        Bill_amt3 = float(x[14]),\n",
    "        Bill_amt4 = float(x[15]),\n",
    "        Bill_amt5 = float(x[16]),\n",
    "        Bill_amt6 = float(x[17]),\n",
    "        Pay_amt1 = float(x[18]),\n",
    "        Pay_amt2 = float(x[19]),\n",
    "        Pay_amt3 = float(x[20]),\n",
    "        Pay_amt4 = float(x[21]),\n",
    "        Pay_amt5 = float(x[22]),\n",
    "        Pay_amt6 = float(x[23])\n",
    "        \n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can do some exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "datos_df = sqlContext.createDataFrame(datosExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|Default|   sex|count|\n",
      "+-------+------+-----+\n",
      "|     No|Female|14349|\n",
      "|     No|  Male| 9015|\n",
      "|    Yes|  Male| 2873|\n",
      "|    Yes|Female| 3763|\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datos_df.select(\"sex\", \"Default\").groupBy(\"Default\", 'sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|Default|Marriage|count|\n",
      "+-------+--------+-----+\n",
      "|     No|  Others|  288|\n",
      "|    Yes|  Others|   89|\n",
      "|     No|  Single|12623|\n",
      "|    Yes| Married| 3206|\n",
      "|    Yes|  Single| 3341|\n",
      "|     No| Married|10453|\n",
      "+-------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datos_df.select(\"Marriage\", \"Default\").groupBy(\"Default\", 'Marriage').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----+\n",
      "|Default|     Education|count|\n",
      "+-------+--------------+-----+\n",
      "|    Yes|    HighSchool| 1237|\n",
      "|     No|       Unknown|  435|\n",
      "|     No|GraduateSchool| 8549|\n",
      "|    Yes|GraduateSchool| 2036|\n",
      "|    Yes|       Unknown|   33|\n",
      "|     No|    University|10700|\n",
      "|     No|    HighSchool| 3680|\n",
      "|    Yes|    University| 3330|\n",
      "+-------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datos_df.select(\"Education\", \"Default\").groupBy(\"Default\", 'Education').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems likely to SQL code. In fact, we can write SQL commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datos_df.registerTempTable(\"datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HighSchool</td>\n",
       "      <td>4917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GraduateSchool</td>\n",
       "      <td>10585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University</td>\n",
       "      <td>14030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0      1\n",
       "0      HighSchool   4917\n",
       "1         Unknown    468\n",
       "2  GraduateSchool  10585\n",
       "3      University  14030"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(sqlContext.sql(\"\"\"\n",
    "        SELECT Education, Count(*) FROM datos GROUP BY Education\n",
    "                    \"\"\").collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said, I will train some Machine Learning Models. First, I will create all categorical variables in 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Gender(x):\n",
    "    if int(x) == 2:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "# Variables for Education\n",
    "    \n",
    "def GraduateSchool(x):\n",
    "    if int(x) == 1:\n",
    "        return 1\n",
    "    else: return 0\n",
    "    \n",
    "def University(x):\n",
    "    if int(x) == 2:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def HighSchool(x):\n",
    "    if int(x) == 3:\n",
    "        return 1\n",
    "    else: return 0\n",
    "    \n",
    "def Unknow(x):\n",
    "    if int(x) == 4 or int(x) == 5 or int(x) == 6:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "    \n",
    "#Marriage variables\n",
    "\n",
    "def Married(x):\n",
    "    if int(x) ==1:\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(AAADefault=1.0, Age=24.0, Bill_amt1=3913.0, Bill_amt2=3102.0, Bill_amt3=689.0, Bill_amt4=0.0, Bill_amt5=0.0, Bill_amt6=0.0, GraduateSchool=0.0, HighSchool=0.0, Limit_Bal=20000.0, Married=1.0, Pay_0=2.0, Pay_2=2.0, Pay_3=-1.0, Pay_4=-1.0, Pay_5=-2.0, Pay_6=-2.0, Pay_amt1=0.0, Pay_amt2=689.0, Pay_amt3=0.0, Pay_amt4=0.0, Pay_amt5=0.0, Pay_amt6=0.0, SchoolUnknown=0.0, University=1.0, sex=1.0),\n",
       " Row(AAADefault=1.0, Age=26.0, Bill_amt1=2682.0, Bill_amt2=1725.0, Bill_amt3=2682.0, Bill_amt4=3272.0, Bill_amt5=3455.0, Bill_amt6=3261.0, GraduateSchool=0.0, HighSchool=0.0, Limit_Bal=120000.0, Married=0.0, Pay_0=-1.0, Pay_2=2.0, Pay_3=0.0, Pay_4=0.0, Pay_5=0.0, Pay_6=2.0, Pay_amt1=0.0, Pay_amt2=1000.0, Pay_amt3=1000.0, Pay_amt4=1000.0, Pay_amt5=0.0, Pay_amt6=2000.0, SchoolUnknown=0.0, University=1.0, sex=1.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "labels = ['Limit_Bal', 'Sex', 'Graduate_School','University','High_School','SchoolUnknown', 'Married',\n",
    "          'Age','Pay0', 'Pay2', 'Pay3', 'Pay4', 'Pay5', 'Pay6', 'Bill_amt1', 'Bill_amt2', 'Bill_amt3','Bill_amt4',\n",
    "         'Bill_amt5','Bill_amt6', 'Pay_amt1','Pay_amt2','Pay_amt3','Pay_amt4','Pay_amt5','Pay_amt6']\n",
    "datosInicio = d2.map(lambda x: Row(\n",
    "        AAADefault = float(x[24]),\n",
    "        Limit_Bal = float(x[1]),\n",
    "        sex = float(Gender(x[2])),\n",
    "        GraduateSchool = float(GraduateSchool(x[3])),\n",
    "        University = float(University(x[3])),\n",
    "        HighSchool = float(HighSchool(x[3])),\n",
    "        SchoolUnknown = float(Unknow(x[3])),\n",
    "        Married = float(Married(x[4])),\n",
    "        Age = float(x[5]),\n",
    "        Pay_0 = float(x[6]),\n",
    "        Pay_2 = float(x[7]),\n",
    "        Pay_3 = float(x[8]),\n",
    "        Pay_4 = float(x[9]),\n",
    "        Pay_5 = float(x[10]),\n",
    "        Pay_6 = float(x[11]),\n",
    "        Bill_amt1 = float(x[12]),\n",
    "        Bill_amt2 = float(x[13]),\n",
    "        Bill_amt3 = float(x[14]),\n",
    "        Bill_amt4 = float(x[15]),\n",
    "        Bill_amt5 = float(x[16]),\n",
    "        Bill_amt6 = float(x[17]),\n",
    "        Pay_amt1 = float(x[18]),\n",
    "        Pay_amt2 = float(x[19]),\n",
    "        Pay_amt3 = float(x[20]),\n",
    "        Pay_amt4 = float(x[21]),\n",
    "        Pay_amt5 = float(x[22]),\n",
    "        Pay_amt6 = float(x[23])        \n",
    "    ))\n",
    "datosInicio.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "datos = spark.createDataFrame(datosInicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [24.0,3913.0,3102.0,689.0,0.0,0.0,0.0,0.0,0.0,20000.0,1.0,2.0,2.0,-1.0,-1.0,-2.0,-2.0,0.0,689.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [26.0,2682.0,1725.0,2682.0,3272.0,3455.0,3261.0,0.0,0.0,120000.0,0.0,-1.0,2.0,0.0,0.0,0.0,2.0,0.0,1000.0,1000.0,1000.0,0.0,2000.0,0.0,1.0,1.0])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "#We will use it for Logistic Regression with LBGS and Tree decision\n",
    "datosMod = datosInicio.map(lambda x: LabeledPoint(x[0], array([x[1::]])))\n",
    "datosMod.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We split the data in train and test\n",
    "datosMod_train, datosMod_test = datosMod.randomSplit([0.8,0.2],1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num observations total: 30000\n",
      "Num observations train: 24071\n",
      "Num observations test: 5929\n",
      "test + train 30000\n"
     ]
    }
   ],
   "source": [
    "print('Num observations total:', datosMod.count())\n",
    "print('Num observations train:', datosMod_train.count())\n",
    "print('Num observations test:', datosMod_test.count())\n",
    "print('test + train', datosMod_train.count() + datosMod_test.count() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([10000.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 43.0, -1.0, 0.0, 0.0, 0.0, -2.0, -2.0, 17560.0, 9829.0, 3604.0, 0.0, 0.0, 0.0, 2537.0, 1000.0, 0.0, 0.0, 0.0, 0.0]), label=1.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "datIni = d2.map(lambda x: Row(\n",
    "        label = float(x[24]),\n",
    "        features =  Vectors.dense(float(x[1]),\n",
    "        float(Gender(x[2])),\n",
    "        float(GraduateSchool(x[3])),\n",
    "        float(University(x[3])),\n",
    "        float(HighSchool(x[3])),\n",
    "        float(Unknow(x[3])),\n",
    "        float(Married(x[4])),\n",
    "        float(x[5]),\n",
    "        float(x[6]),\n",
    "        float(x[7]),\n",
    "        float(x[8]),\n",
    "        float(x[9]),\n",
    "        float(x[10]),\n",
    "        float(x[11]),\n",
    "        float(x[12]),\n",
    "        float(x[13]),\n",
    "        float(x[14]),\n",
    "        float(x[15]),\n",
    "        float(x[16]),\n",
    "        float(x[17]),\n",
    "        float(x[18]),\n",
    "        float(x[19]),\n",
    "        float(x[20]),\n",
    "        float(x[21]),\n",
    "        float(x[22]),\n",
    "        float(x[23])        \n",
    "    )))\n",
    "sdf = datIni.toDF()\n",
    "LR_train, LR_test = sdf.randomSplit([0.8,0.2],1234)\n",
    "LR_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.291 Seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from time import time\n",
    "t0 = time()\n",
    "blor = LogisticRegression(maxIter=5)\n",
    "blorModel = blor.fit(LR_train)\n",
    "t1 = time() - t0\n",
    "print(round(t1,3),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  Coeficientes:\n",
      "   [-8.74004462692e-07,-0.10126018842,0.110234293833,0.00919486676759,-0.035717929177,-0.664689697551,0.152913729597,0.00730709213761,0.424251048269,0.146642792394,0.0810527408026,0.0331709378994,0.0228535873652,0.0127520633367,-7.60708531435e-07,-5.24216388531e-07,-5.50630020876e-07,-3.59203153813e-07,-2.08453540459e-07,-9.60976203915e-08,-6.67696430106e-06,-3.95024694158e-06,-3.08198844462e-06,-3.74317944484e-06,-3.66555457151e-06,-3.08175906809e-06]\n",
      "\n",
      "2.  Intercept: -1.2508486105911831\n"
     ]
    }
   ],
   "source": [
    "print('1.  Coeficientes:\\n  ', blorModel.coefficients)\n",
    "print('\\n2.  Intercept:', blorModel.intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the ROC curve: 0.7229381001197289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeficientes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Limit_Bal</th>\n",
       "      <td>-8.700000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-1.012602e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduate_School</th>\n",
       "      <td>1.102343e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University</th>\n",
       "      <td>9.194870e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High_School</th>\n",
       "      <td>-3.571793e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SchoolUnknown</th>\n",
       "      <td>-6.646897e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>1.529137e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>7.307090e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay0</th>\n",
       "      <td>4.242511e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay2</th>\n",
       "      <td>1.466428e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay3</th>\n",
       "      <td>8.105274e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay4</th>\n",
       "      <td>3.317094e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay5</th>\n",
       "      <td>2.285359e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay6</th>\n",
       "      <td>1.275206e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill_amt1</th>\n",
       "      <td>-7.600000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill_amt2</th>\n",
       "      <td>-5.200000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill_amt3</th>\n",
       "      <td>-5.500000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill_amt4</th>\n",
       "      <td>-3.600000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill_amt5</th>\n",
       "      <td>-2.100000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill_amt6</th>\n",
       "      <td>-1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_amt1</th>\n",
       "      <td>-6.680000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_amt2</th>\n",
       "      <td>-3.950000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_amt3</th>\n",
       "      <td>-3.080000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_amt4</th>\n",
       "      <td>-3.740000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_amt5</th>\n",
       "      <td>-3.670000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pay_amt6</th>\n",
       "      <td>-3.080000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-1.250849e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coeficientes\n",
       "Limit_Bal       -8.700000e-07\n",
       "Sex             -1.012602e-01\n",
       "Graduate_School  1.102343e-01\n",
       "University       9.194870e-03\n",
       "High_School     -3.571793e-02\n",
       "SchoolUnknown   -6.646897e-01\n",
       "Married          1.529137e-01\n",
       "Age              7.307090e-03\n",
       "Pay0             4.242511e-01\n",
       "Pay2             1.466428e-01\n",
       "Pay3             8.105274e-02\n",
       "Pay4             3.317094e-02\n",
       "Pay5             2.285359e-02\n",
       "Pay6             1.275206e-02\n",
       "Bill_amt1       -7.600000e-07\n",
       "Bill_amt2       -5.200000e-07\n",
       "Bill_amt3       -5.500000e-07\n",
       "Bill_amt4       -3.600000e-07\n",
       "Bill_amt5       -2.100000e-07\n",
       "Bill_amt6       -1.000000e-07\n",
       "Pay_amt1        -6.680000e-06\n",
       "Pay_amt2        -3.950000e-06\n",
       "Pay_amt3        -3.080000e-06\n",
       "Pay_amt4        -3.740000e-06\n",
       "Pay_amt5        -3.670000e-06\n",
       "Pay_amt6        -3.080000e-06\n",
       "intercept       -1.250849e+00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labels = ['Limit_Bal', 'Sex', 'Graduate_School','University','High_School','SchoolUnknown', 'Married',\n",
    "          'Age','Pay0', 'Pay2', 'Pay3', 'Pay4', 'Pay5', 'Pay6', 'Bill_amt1', 'Bill_amt2', 'Bill_amt3','Bill_amt4',\n",
    "         'Bill_amt5','Bill_amt6', 'Pay_amt1','Pay_amt2','Pay_amt3','Pay_amt4','Pay_amt5','Pay_amt6', 'intercept']\n",
    "coef = []\n",
    "for i in blorModel.coefficients:\n",
    "    coef.append(i)\n",
    "coef.append(blorModel.intercept)\n",
    "stats = pd.DataFrame(coef, index=labels, columns=['Coeficientes']).round(8)\n",
    "print('Area Under the ROC curve:',blorModel.summary.areaUnderROC)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TRAIN:\n",
      "   Total sum of well predicted: 19218\n",
      "   % of well predicted 80.36632793877807 %. \n"
     ]
    }
   ],
   "source": [
    "pred = blorModel.transform(LR_train)\n",
    "predicciones = pred.select('label','prediction')\n",
    "Truepredicciones = predicciones.filter(predicciones.label == predicciones.prediction).count()\n",
    "print('Accuracy with TRAIN:')\n",
    "print('   Total sum of well predicted:', Truepredicciones)\n",
    "print('   % of well predicted', Truepredicciones/predicciones.count()*100,'%. ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TEST:\n",
      "   Total sum of well predicted: 4873\n",
      "   % of well predicted 80.05585674388041 %. \n"
     ]
    }
   ],
   "source": [
    "predTest = blorModel.transform(LR_test)\n",
    "prediccionesTest = predTest.select('label','prediction')\n",
    "TrueprediccionesTest = prediccionesTest.filter(prediccionesTest.label == prediccionesTest.prediction).count()\n",
    "print('Accuracy with TEST:')\n",
    "print('   Total sum of well predicted:', TrueprediccionesTest)\n",
    "print('   % of well predicted', TrueprediccionesTest/prediccionesTest.count()*100,'%. ' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datosMod = datosInicio.map(lambda x: LabeledPoint(x[0], array([x[1::]])))\n",
    "datosPred = datosInicio.map(lambda x: x[1::])\n",
    "datosPred_train, datosPred_test = datosPred.randomSplit([0.8,0.2],1234)\n",
    "datosMod_train, datosMod_test = datosMod.randomSplit([0.8,0.2],1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.042 Seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "logit_model = LogisticRegressionWithLBFGS.train(datosMod_train)\n",
    "t1 = time() - t0\n",
    "print(round(t1,3),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0042, -0.0, 0.0, 0.0, 0.0, -0.0, 0.0, -1.0753, -1.2225, -0.0, 0.1859, 0.5875, 0.0881, 0.0567, 0.0245, 0.0157, 0.0216, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -2.4474, -1.2054, -0.1176])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weihths\n",
    "logit_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LinearClassificationModel.setThreshold of (weights=[0.00419717371539,-6.70647031126e-06,2.92195157448e-06,1.85245123648e-06,8.48434659793e-07,-1.10559421432e-06,1.47600726139e-06,-1.07534939407,-1.22247101208,-8.12742676273e-07,0.185913882623,0.587501004966,0.0881274981419,0.0566994973616,0.0244827342975,0.0156947491265,0.0216215913302,-1.46151573395e-05,-1.19903117558e-05,-2.72322153108e-06,-2.346285812e-06,-5.55896968225e-06,-3.388310023e-06,-2.44735322471,-1.20544762595,-0.117595200924], intercept=0.0)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.setThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TRAIN:\n",
      "   Total sum of well predicted: 19558\n",
      "   % of well predicted 81.2512982426987 %. \n"
     ]
    }
   ],
   "source": [
    "#Train sample\n",
    "pred = logit_model.predict(datosPred_train)\n",
    "cont = datosMod_train.map(lambda x: x.label).zip(pred)\n",
    "countTrue = cont.filter(lambda v: v[0]==v[1]).count()\n",
    "print('Accuracy with TRAIN:')\n",
    "print('   Total sum of well predicted:', countTrue)\n",
    "print('   % of well predicted', countTrue/cont.count()*100,'%. ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TEST:\n",
      "   Total sum of well predicted: 4800\n",
      "   % of well predicted 80.95800303592512 %. \n"
     ]
    }
   ],
   "source": [
    "#Test sample\n",
    "predTest = logit_model.predict(datosPred_test)\n",
    "contTest = datosMod_test.map(lambda x: x.label).zip(predTest)\n",
    "countTrueTest = contTest.filter(lambda v: v[0]==v[1]).count()\n",
    "print('Accuracy with TEST:')\n",
    "print('   Total sum of well predicted:', countTrueTest)\n",
    "print('   % of well predicted', countTrueTest/contTest.count()*100,'%. ' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.053 Seconds\n",
      "DecisionTreeModel classifier of depth 7 with 213 nodes\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "t0 = time()\n",
    "tree_model = DecisionTree.trainClassifier(datosMod_train, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                         maxDepth=7)\n",
    "t1 = time() - t0\n",
    "print(round(t1,3),'Seconds')\n",
    "print(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TRAIN:\n",
      "   Total sum of well predicted: 19972\n",
      "   % of well predicted 82.971210169914 %.\n"
     ]
    }
   ],
   "source": [
    "pred = tree_model.predict(datosMod_train.map(lambda x: x.features))\n",
    "comp = datosMod_train.map(lambda x: x.label).zip(pred) #zip es para mezclar los dos vectores\n",
    "PredicTrue = comp.filter(lambda x: x[0]==x[1]).count()\n",
    "print('Accuracy with TRAIN:')\n",
    "print('   Total sum of well predicted:', PredicTrue)\n",
    "print('   % of well predicted', PredicTrue/pred.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TEST:\n",
      "   Total sum of well predicted: 4825\n",
      "   % of well predicted 81.37965930173723 %.\n"
     ]
    }
   ],
   "source": [
    "predTest = tree_model.predict(datosMod_test.map(lambda x: x.features))\n",
    "compTest = datosMod_test.map(lambda x: x.label).zip(predTest) #zip es para mezclar los dos vectores\n",
    "PredicTrueTest = compTest.filter(lambda x: x[0]==x[1]).count()\n",
    "print('Accuracy with TEST:')\n",
    "print('   Total sum of well predicted:', PredicTrueTest)\n",
    "print('   % of well predicted', PredicTrueTest/predTest.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207.809 Seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(sdf)\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(sdf)\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "model = pipeline.fit(LR_train)\n",
    "t1 = time() - t0\n",
    "print(round(t1,3),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TRAIN:\n",
      "   Total sum of well predicted: 19698\n",
      "   % of well predicted 82.37360431564422 %.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(LR_train)\n",
    "predR = predictions.select(\"predictedLabel\", \"label\")\n",
    "TruepredR = predR.filter(predR.predictedLabel == predR.label).count()\n",
    "print('Accuracy with TRAIN:')\n",
    "print('   Total sum of well predicted:', TruepredR)\n",
    "print('   % of well predicted', TruepredR/predR.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TEST:\n",
      "   Total sum of well predicted: 4972\n",
      "   % of well predicted 81.68227369804501 %.\n"
     ]
    }
   ],
   "source": [
    "predictionsTest = model.transform(LR_test)\n",
    "predRTest = predictionsTest.select(\"predictedLabel\", \"label\")\n",
    "TruepredRTest = predRTest.filter(predRTest.predictedLabel == predRTest.label).count()\n",
    "print('Accuracy with TEST:')\n",
    "print('   Total sum of well predicted:', TruepredRTest)\n",
    "print('   % of well predicted', TruepredRTest/predRTest.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196.444 Seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(sdf)\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(sdf)\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=20)\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "modelGB = pipeline.fit(LR_train)\n",
    "t1 = time() - t0\n",
    "print(round(t1,3),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TRAIN:\n",
      "   Total sum of well predicted: 19877\n",
      "   % of well predicted 83.12215113118387 %.\n"
     ]
    }
   ],
   "source": [
    "predictionsGB = modelGB.transform(LR_train)\n",
    "predR = predictionsGB.select(\"prediction\", \"label\")\n",
    "TruepredR = predR.filter(predR.prediction == predR.label).count()\n",
    "print('Accuracy with TRAIN:')\n",
    "print('   Total sum of well predicted:', TruepredR)\n",
    "print('   % of well predicted', TruepredR/predR.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TEST:\n",
      "   Total sum of well predicted: 4982\n",
      "   % of well predicted 81.84655823886973 %.\n"
     ]
    }
   ],
   "source": [
    "predictionsGBTest = modelGB.transform(LR_test)\n",
    "predRTest = predictionsGBTest.select(\"prediction\", \"label\")\n",
    "TruepredRTest = predRTest.filter(predRTest.prediction == predRTest.label).count()\n",
    "print('Accuracy with TEST:')\n",
    "print('   Total sum of well predicted:', TruepredRTest)\n",
    "print('   % of well predicted', TruepredRTest/predRTest.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.471 Seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "t0 = time()\n",
    "layers = [26, 9, 5]\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "modelMPC = trainer.fit(LR_train)\n",
    "t1 = time()-t0\n",
    "print(round(t1,3),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TRAIN:\n",
      "   Total sum of well predicted: 18640\n",
      "   % of well predicted 77.94923263496842 %.\n"
     ]
    }
   ],
   "source": [
    "predictionsMPC = modelMPC.transform(LR_train)\n",
    "predR = predictionsMPC.select(\"prediction\", \"label\")\n",
    "TruepredR = predR.filter(predR.prediction == predR.label).count()\n",
    "print('Accuracy with TRAIN:')\n",
    "print('   Total sum of well predicted:', TruepredR)\n",
    "print('   % of well predicted', TruepredR/predR.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TEST:\n",
      "   Total sum of well predicted: 4724\n",
      "   % of well predicted 77.60801708559225 %.\n"
     ]
    }
   ],
   "source": [
    "predictionsMPCTest = modelMPC.transform(LR_test)\n",
    "predRTest = predictionsMPCTest.select(\"prediction\", \"label\")\n",
    "TruepredRTest = predRTest.filter(predRTest.prediction == predRTest.label).count()\n",
    "print('Accuracy with TEST:')\n",
    "print('   Total sum of well predicted:', TruepredRTest)\n",
    "print('   % of well predicted', TruepredRTest/predRTest.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.362 Seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "modelSVM = SVMWithSGD.train(datosMod_train, iterations=1500)\n",
    "t1 = time()-t0\n",
    "print(round(t1,3),'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=0.0, label=1.0),\n",
       " Row(prediction=0.0, label=0.0),\n",
       " Row(prediction=0.0, label=0.0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predR.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TRAIN:\n",
      "   Total sum of well predicted: 5668\n",
      "   % of well predicted 23.547006771633917 %.\n"
     ]
    }
   ],
   "source": [
    "predictionsSVM = modelSVM.predict(datosPred_train)\n",
    "predR = datosMod_train.map(lambda x: x.label).zip(predictionsSVM)\n",
    "TruepredR = predR.filter(lambda v: v[0]==v[1]).count()\n",
    "print('Accuracy with TRAIN:')\n",
    "print('   Total sum of well predicted:', TruepredR)\n",
    "print('   % of well predicted', TruepredR/predR.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TEST:\n",
      "   Total sum of well predicted: 1386\n",
      "   % of well predicted 23.376623376623375 %.\n"
     ]
    }
   ],
   "source": [
    "predictionsSVMTest = modelSVM.predict(datosPred_test)\n",
    "predRTest = datosMod_test.map(lambda x: x.label).zip(predictionsSVMTest)\n",
    "TruepredRTest = predRTest.filter(lambda v: v[0]==v[1]).count()\n",
    "print('Accuracy with TEST:')\n",
    "print('   Total sum of well predicted:', TruepredRTest)\n",
    "print('   % of well predicted', TruepredRTest/predRTest.count()*100,'%.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, SVM is not a good method!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
